{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Langchain and OpenAI\n",
    "\n",
    "### In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with Langchain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt, templates, module and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000002043EE16590> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002043EE48690> root_client=<openai.OpenAI object at 0x000002043EBAB3D0> root_async_client=<openai.AsyncOpenAI object at 0x000002043EE54210> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response from LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a type of artificial intelligence that is designed to generate new content, such as text, images, music, or even video, by learning from existing data. Unlike traditional AI, which is often focused on recognizing patterns or making predictions based on input data, generative AI creates new data that is similar to the training data it was exposed to.\\n\\nKey techniques in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These consist of two neural networks, a generator and a discriminator, that work against each other. The generator creates new data instances, while the discriminator evaluates them for authenticity. Through this adversarial process, the generator improves its ability to produce realistic data.\\n\\n2. **Variational Autoencoders (VAEs):** These models learn to encode input data into a compressed representation and then decode it back to the original data. During this process, they can generate new data by sampling from the latent space they learn.\\n\\n3. **Transformer Models:** These are often used for text generation tasks. Models like GPT (Generative Pre-trained Transformer) operate on this principle, generating coherent and contextually relevant text by predicting the next word in a sequence.\\n\\nGenerative AI has numerous applications, including:\\n\\n- **Content Creation:** Automated generation of articles, stories, or social media content.\\n- **Art and Design:** Creating new images, designs, or even music compositions.\\n- **Entertainment:** Developing virtual characters, game levels, or plots.\\n- **Data Augmentation:** Creating synthetic data to enhance machine learning model training.\\n- **Personalization:** Generating personalized recommendations or interaction experiences.\\n\\nOverall, generative AI is a powerful tool that can aid creativity, increase productivity, and offer new solutions across various fields.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 354, 'prompt_tokens': 13, 'total_tokens': 367, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None} id='run-4839d772-53f4-4e39-be35-be1c55e1a921-0' usage_metadata={'input_tokens': 13, 'output_tokens': 354, 'total_tokens': 367, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based omn the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based omn the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is a platform designed to enhance the development and deployment of applications that utilize large language models (LLMs). It aims to improve the performance, efficiency, and reliability of LLM applications by providing tools for debugging, testing, and monitoring. Langsmith offers features that allow developers to track the behavior of language models, identify issues, and optimize their applications for better user experiences. This platform is particularly useful in the context of rapidly evolving AI technologies, where understanding and fine-tuning model interactions are crucial for delivering robust applications.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 33, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None}, id='run-dddff823-2b99-4e84-bfb0-caf593cedde0-0', usage_metadata={'input_tokens': 33, 'output_tokens': 105, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Chain\n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"can you tell me about Langsmith?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool developed by LangChain designed to enhance the development of applications using language models. It provides robust features for testing and debugging, allowing developers to gain deeper insights into how their language model-based applications are performing. Langsmith offers capabilities for tracing, evaluation, and monitoring, which are essential for refining the interaction between language models and application logic. By using Langsmith, developers can iteratively improve their applications, ensuring better alignment with desired outcomes and more reliable performance in production environments.\n"
     ]
    }
   ],
   "source": [
    "## str output Parser\n",
    "\n",
    "from langchain_core.output_parsers import  StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
